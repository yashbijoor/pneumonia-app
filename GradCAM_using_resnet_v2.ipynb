{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import cv2\n",
        "from random import shuffle\n",
        "from tqdm import tqdm\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras import layers,models\n",
        "from keras.models import Sequential\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "import numpy as np\n",
        "from keras.models import load_model\n",
        "import cv2\n",
        "\n",
        "from tensorflow import keras\n",
        "from keras.layers import Input\n",
        "from keras.models import Model\n",
        "from keras.callbacks import Callback\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#from tensorflow.keras.preprocessing import image\n",
        "from keras.models import Model\n",
        "from keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from keras.applications import ResNet50\n",
        "from keras.applications.resnet import preprocess_input, decode_predictions\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.optimizers import Adam\n",
        "import cv2\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.applications.vgg16 import VGG16\n",
        "from keras.preprocessing import image\n",
        "from keras.applications.vgg16 import preprocess_input\n",
        "from skimage.segmentation import mark_boundaries\n",
        "import keras.utils as image\n",
        "from keras.utils import load_img,img_to_array,array_to_img\n",
        "from matplotlib import cm\n",
        "\n",
        "from collections import Counter\n",
        "from google.colab import drive\n"
      ],
      "metadata": {
        "id": "wp3xmbqWpEpP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v3Sq-tC7pAOj",
        "outputId": "a49a3b1a-b81c-43da-af09-8251f1f9e55e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "94765736/94765736 [==============================] - 0s 0us/step\n",
            "Found 5216 images belonging to 2 classes.\n",
            "Found 624 images belonging to 2 classes.\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Load pre-trained ResNet50 model\n",
        "base_model = ResNet50(include_top=False, weights='imagenet', input_shape=(224, 224, 3))\n",
        "\n",
        "# Freeze layers\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Add custom head\n",
        "x = layers.GlobalAveragePooling2D()(base_model.output)\n",
        "x = layers.Dense(1024, activation='relu')(x)\n",
        "x = layers.Dense(1, activation='sigmoid')(x)\n",
        "model = models.Model(inputs=base_model.input, outputs=x)\n",
        "\n",
        "# Compile model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Data preprocessing\n",
        "train_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
        "test_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
        "\n",
        "train_data = train_datagen.flow_from_directory(\n",
        "        '/content/drive/MyDrive/chest_xray/train',\n",
        "        target_size=(224, 224),\n",
        "        batch_size=32,\n",
        "        class_mode='binary')\n",
        "\n",
        "test_data = test_datagen.flow_from_directory(\n",
        "        '/content/drive/MyDrive/chest_xray/chest_xray/test',\n",
        "        target_size=(224, 224),\n",
        "        batch_size=32,\n",
        "        class_mode='binary')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Load the pre-trained ResNet50V2 model\n",
        "base_model = keras.applications.ResNet50V2(weights='imagenet', include_top=False)\n",
        "\n",
        "# Freeze the layers in the base model\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Create a new model on top of the base model\n",
        "inputs = layers.Input(shape=(224, 224, 3))\n",
        "x = base_model(inputs)\n",
        "x = layers.GlobalAveragePooling2D()(x)\n",
        "x = layers.Dense(1, activation='relu')(x)\n",
        "model = models.Model(inputs, x)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Load the pneumonia dataset\n",
        "train_dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    '/content/drive/MyDrive/chest_xray/train',\n",
        "    seed=123,\n",
        "    image_size=(224, 224),\n",
        "    batch_size=32\n",
        ")\n",
        "val_dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    '/content/drive/MyDrive/chest_xray/chest_xray/val',\n",
        "    seed=123,\n",
        "    image_size=(224, 224),\n",
        "    batch_size=32\n",
        ")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KxfWU-Q7p-hr",
        "outputId": "f2c0aac4-840f-4880-d6e6-a1e11ddf04d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50v2_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "94668760/94668760 [==============================] - 1s 0us/step\n",
            "Found 5216 files belonging to 2 classes.\n",
            "Found 16 files belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(train_dataset, validation_data=val_dataset, epochs=1)"
      ],
      "metadata": {
        "id": "MYd1-9rmqFdi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fc0b5e45-8c76-42b3-ef30-847e0036b305"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "163/163 [==============================] - 395s 2s/step - loss: 3.9205 - accuracy: 0.7429 - val_loss: 7.6246 - val_accuracy: 0.5000\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f3b9bb4e980>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#model.summary()"
      ],
      "metadata": {
        "id": "rEF-xdzr7L7B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#model.save('/content/drive/MyDrive/Model/gradcam2.h5')"
      ],
      "metadata": {
        "id": "vJyWN2xy8Ve4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the pre-trained ResNet50V2 model\n",
        "'''\n",
        "input_tensor = layers.Input(shape=(224,224, 3))\n",
        "base_model = keras.applications.ResNet50V2(weights='imagenet', include_top=True, input_tensor=input_tensor)\n",
        "\n",
        "# Freeze all the layers in the base model\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Add a new output layer\n",
        "x = base_model.layers[-2].output\n",
        "x = keras.layers.Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "# Create the new model\n",
        "model = keras.models.Model(inputs=base_model.input, outputs=x)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Load your dataset\n",
        "train_dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    '/content/drive/MyDrive/chest_xray/train',\n",
        "    image_size=(224, 224),\n",
        "    batch_size=32\n",
        ")\n",
        "\n",
        "val_dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    '/content/drive/MyDrive/chest_xray/chest_xray/val',\n",
        "    image_size=(224, 224),\n",
        "    batch_size=32\n",
        ")\n",
        "'''\n",
        "\n",
        "# Load the pre-trained ResNet50V2 model\n",
        "input_tensor = layers.Input(shape=(224,224, 3))\n",
        "base_model = keras.applications.ResNet50V2(weights='imagenet', include_top=False, input_tensor=input_tensor)\n",
        "inputs = layers.Input(shape=(224, 224, 3))\n",
        "x = base_model(inputs)\n",
        "x = layers.GlobalAveragePooling2D()(x)\n",
        "x = layers.Dense(1, activation='relu')(x)\n",
        "model = models.Model(inputs, x)\n",
        "\n",
        "# Freeze all the layers in the base model except the last t\n",
        "t = 20\n",
        "for layer in base_model.layers[:-t]:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Add a new output layer\n",
        "'''\n",
        "x = base_model.layers[-2].output\n",
        "x = keras.layers.Dense(1, activation='sigmoid')(x)\n",
        "'''\n",
        "# Create the new model\n",
        "#model = keras.models.Model(inputs=base_model.input, outputs=x)\n",
        "\n",
        "# Set up data augmentation\n",
        "data_augmentation = keras.Sequential(\n",
        "    [\n",
        "        layers.RandomFlip(\"horizontal\"),\n",
        "        layers.RandomRotation(0.1),\n",
        "        layers.RandomZoom(0.1),\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Compile the model with a lower learning rate and binary crossentropy loss\n",
        "model.compile(optimizer=keras.optimizers.Adam(lr=0.0001), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Load your dataset with data augmentation\n",
        "train_dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    '/content/drive/MyDrive/chest_xray/train',\n",
        "    image_size=(224, 224),\n",
        "    batch_size=32\n",
        ")\n",
        "train_dataset = train_dataset.map(lambda x, y: (data_augmentation(x), y))\n",
        "\n",
        "val_dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    '/content/drive/MyDrive/chest_xray/test',\n",
        "    image_size=(224, 224),\n",
        "    batch_size=32\n",
        ")\n",
        "\n",
        "# Train the model for the first few epochs with the base layers frozen\n",
        "model.fit(train_dataset, epochs=1, validation_data=val_dataset)\n",
        "\n",
        "# Unfreeze the last t layers\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = True\n",
        "\n",
        "# Recompile the model with a lower learning rate\n",
        "model.compile(optimizer=keras.optimizers.Adam(lr=0.00001), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Fine-tune the model for additional epochs\n",
        "model.fit(train_dataset, epochs=1, validation_data=val_dataset)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "AaLSvxle_T41",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "11a1ba7e-3f47-4829-d089-db8b599a90fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 5216 files belonging to 2 classes.\n",
            "Found 624 files belonging to 2 classes.\n",
            "163/163 [==============================] - 174s 1s/step - loss: 0.7812 - accuracy: 0.8602 - val_loss: 2.4407 - val_accuracy: 0.8029\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "163/163 [==============================] - 135s 599ms/step - loss: 0.7601 - accuracy: 0.8334 - val_loss: 5.7187 - val_accuracy: 0.6250\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f3a63fad870>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "history = model.fit(train_dataset, epochs=1, validation_data=val_dataset)\n",
        "\n"
      ],
      "metadata": {
        "id": "C426ek62yTYH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3dbccb16-5011-4ba1-bc42-ef93f84eac64"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "163/163 [==============================] - 96s 577ms/step - loss: 0.4938 - accuracy: 0.8094 - val_loss: 3.1052 - val_accuracy: 0.6683\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Unfreeze some layers\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = True\n",
        "\n",
        "# Recompile the model\n",
        "model.compile(optimizer=keras.optimizers.Adam(lr=0.0001), loss='binary_crossentropy', metrics=['accuracy'])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ahRlnLe9yVho",
        "outputId": "776ea4bf-1fb2-4942-885d-852e672db9e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Fine-tune the model\n",
        "history = model.fit(train_dataset, epochs=1, validation_data=val_dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XZ5gWUNayXK2",
        "outputId": "7a07c9da-7481-49b8-f787-6e1f089ffbdd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "163/163 [==============================] - 45s 218ms/step - loss: 0.1458 - accuracy: 0.9396 - val_loss: 0.2547 - val_accuracy: 0.9375\n",
            "Epoch 2/10\n",
            "163/163 [==============================] - 38s 224ms/step - loss: 0.0782 - accuracy: 0.9678 - val_loss: 0.2930 - val_accuracy: 0.8750\n",
            "Epoch 3/10\n",
            "163/163 [==============================] - 37s 217ms/step - loss: 0.0475 - accuracy: 0.9831 - val_loss: 0.6866 - val_accuracy: 0.8125\n",
            "Epoch 4/10\n",
            "163/163 [==============================] - 37s 217ms/step - loss: 0.0410 - accuracy: 0.9856 - val_loss: 1.1520 - val_accuracy: 0.6250\n",
            "Epoch 5/10\n",
            "163/163 [==============================] - 38s 224ms/step - loss: 0.0294 - accuracy: 0.9891 - val_loss: 1.5436 - val_accuracy: 0.5625\n",
            "Epoch 6/10\n",
            "163/163 [==============================] - 37s 215ms/step - loss: 0.0203 - accuracy: 0.9923 - val_loss: 1.0430 - val_accuracy: 0.6250\n",
            "Epoch 7/10\n",
            "163/163 [==============================] - 38s 223ms/step - loss: 0.0231 - accuracy: 0.9921 - val_loss: 0.6587 - val_accuracy: 0.7500\n",
            "Epoch 8/10\n",
            "163/163 [==============================] - 38s 223ms/step - loss: 0.0144 - accuracy: 0.9944 - val_loss: 1.0787 - val_accuracy: 0.7500\n",
            "Epoch 9/10\n",
            "163/163 [==============================] - 36s 213ms/step - loss: 0.0132 - accuracy: 0.9954 - val_loss: 3.1323 - val_accuracy: 0.5000\n",
            "Epoch 10/10\n",
            "163/163 [==============================] - 37s 217ms/step - loss: 0.0134 - accuracy: 0.9952 - val_loss: 1.5643 - val_accuracy: 0.7500\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#model.save_weights('/content/drive/MyDrive/Tumor2/my_model_new_weights.h5')"
      ],
      "metadata": {
        "id": "UJ957A_0zY89"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Load the pre-trained ResNet50V2 model\n",
        "base_model = keras.applications.ResNet50V2(weights='imagenet', include_top=False)\n",
        "#base_model=model\n",
        "# Get the input tensor shape\n",
        "input_tensor_shape = (224, 224, 3)\n",
        "batch_size=32\n",
        "# Freeze all the layers in the base model\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Add a new output layer\n",
        "x = base_model.layers[-2].output\n",
        "x = keras.layers.Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "# Create the new model\n",
        "model = keras.models.Model(inputs=base_model.input, outputs=x)\n",
        "\n",
        "# Load your dataset\n",
        "train_dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    '/content/drive/MyDrive/chest_xray/train',\n",
        "    image_size=(input_tensor_shape[0], input_tensor_shape[1]),\n",
        "    batch_size=batch_size\n",
        ")\n"
      ],
      "metadata": {
        "id": "7dob0PkKyZmb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a3f2def2-b652-47aa-e3b6-d390f3e99de4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 5216 files belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer=keras.optimizers.Adam(lr=0.0001), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "# Fine-tune the model\n",
        "y_train = np.expand_dims(y_train, axis=-1)\n",
        "y_val = np.expand_dims(y_val, axis=-1)\n",
        "history = model.fit(train_dataset, epochs=1, validation_data=val_dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 290
        },
        "id": "MVlCYymFa4TK",
        "outputId": "43d454c4-2753-4968-bebb-388372dce0e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-ecd1bad95aa1>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'binary_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# Fine-tune the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0my_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0my_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'y_train' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Load the image and preprocess it\n",
        "img_path = '/content/drive/MyDrive/chest_xray/val/PNEUMONIA/person1946_bacteria_4875.jpeg'\n",
        "img = image.load_img(img_path, target_size=(224, 224))\n",
        "x = image.img_to_array(img)\n",
        "x = np.expand_dims(x, axis=0)\n",
        "x = tf.keras.applications.resnet50.preprocess_input(x)\n",
        "\n",
        "# Get the last convolutional layer\n",
        "last_conv_layer = model.get_layer('conv5_block3_out')\n",
        "\n",
        "# Compute the gradient of the class output value with respect to the feature map of the last convolutional layer\n",
        "grad_model = tf.keras.models.Model([model.inputs], [model.output, last_conv_layer.output])\n",
        "with tf.GradientTape() as tape:\n",
        "    preds, conv_outputs = grad_model(x)\n",
        "    class_idx = tf.argmax(preds[0])\n",
        "    loss = preds[:, class_idx]\n",
        "grads = tape.gradient(loss, conv_outputs)[0]\n",
        "\n",
        "# Compute the channel-wise mean of the gradients\n",
        "weights = tf.reduce_mean(grads, axis=(0, 1))\n",
        "\n",
        "# Multiply each channel in the feature map array by \"how important this channel is\" with regard to the class\n",
        "cam = np.ones(conv_outputs.shape[1:3], dtype=np.float32)\n",
        "for i, w in enumerate(weights):\n",
        "    cam += w * conv_outputs[0, :, :, i]\n",
        "# Normalize the heatmap between 0 and 255\n",
        "heatmap = cam.numpy()\n",
        "heatmap = cv2.resize(heatmap, (224,224))\n",
        "heatmap = np.maximum(heatmap, 0)\n",
        "heatmap = (heatmap - np.min(heatmap)) / (np.max(heatmap) - np.min(heatmap) + 1e-8)\n",
        "heatmap = (heatmap * 255).astype(np.uint8)\n",
        "# Apply a color map to the heatmap\n",
        "jet = cm.get_cmap(\"jet\")\n",
        "heatmap = jet(heatmap)\n",
        "heatmap = np.uint8(heatmap * 255)\n",
        "\n",
        "# Convert the heatmap to RGB format\n",
        "heatmap = cv2.cvtColor(heatmap, cv2.COLOR_RGBA2RGB)\n",
        "\n",
        "# Resize the heatmap to be the same size as the original image\n",
        "heatmap = cv2.resize(heatmap, (224,224))\n",
        "\n",
        "# Combine the heatmap with the original image\n",
        "superimposed_img = cv2.addWeighted(np.array(img), 0.5, heatmap, 0.5, 0)\n",
        "\n",
        "# Show the result\n",
        "plt.imshow(superimposed_img)\n",
        "plt.axis('off')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "Qnszo7PDABgR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 433
        },
        "outputId": "301f0b20-3a8e-431a-ed00-9d919e28e914"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "InvalidArgumentError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-5006564ad3fa>\u001b[0m in \u001b[0;36m<cell line: 20>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;31m# Compute the channel-wise mean of the gradients\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0mweights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce_mean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;31m# Multiply each channel in the feature map array by \"how important this channel is\" with regard to the class\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     53\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     54\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mInvalidArgumentError\u001b[0m: {{function_node __wrapped__Mean_device_/job:localhost/replica:0/task:0/device:GPU:0}} Invalid reduction dimension (1 for input with 1 dimension(s) [Op:Mean]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Load an image to predict\n",
        "#img_path = '/content/drive/MyDrive/chest_xray/val/PNEUMONIA/person1946_bacteria_4875.jpeg'\n",
        "img = image.load_img(img_path, target_size=(224, 224))\n",
        "img_array = image.img_to_array(img)\n",
        "img_array = np.expand_dims(img_array, axis=0)\n",
        "img_array = img_array / 255.0\n",
        "\n",
        "# Predict the class probabilities of the image\n",
        "probs = model.predict(img_array)[0]\n",
        "\n",
        "# Print the predicted class\n",
        "if probs[0] > 0.5:\n",
        "    print('Pneumonia detected with probability:', probs[0])\n",
        "else:\n",
        "    print('No Pneumonia detected with probability:', 1 - probs[0])\n"
      ],
      "metadata": {
        "id": "Dvb9RE6P00Ek"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#model.save('/content/drive/MyDrive/Tumor2/tumor_new_model.h5')"
      ],
      "metadata": {
        "id": "56IKlpznM_gG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Set the conv3_block3_out layer to be trainable\n",
        "base_model.get_layer('conv5_block3_out').trainable = True"
      ],
      "metadata": {
        "id": "3B_SAeIZOOpC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "history = model.fit(train_dataset, epochs=100, validation_data=val_dataset)"
      ],
      "metadata": {
        "id": "oNnhRy1o5c2g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Load the image and preprocess it\n",
        "img_path = '/content/drive/MyDrive/chest_xray/val/PNEUMONIA/person1946_bacteria_4875.jpeg'\n",
        "img = image.load_img(img_path, target_size=(224, 224))\n",
        "x = image.img_to_array(img)\n",
        "x = np.expand_dims(x, axis=0)\n",
        "x = tf.keras.applications.resnet50.preprocess_input(x)\n",
        "\n",
        "# Get the last convolutional layer\n",
        "last_conv_layer = model.get_layer('conv5_block3_out')\n",
        "\n",
        "# Compute the gradient of the class output value with respect to the feature map of the last convolutional layer\n",
        "grad_model = tf.keras.models.Model([model.inputs], [model.output, last_conv_layer.output])\n",
        "with tf.GradientTape() as tape:\n",
        "    preds, conv_outputs = grad_model(x)\n",
        "    class_idx = tf.argmax(preds[0])\n",
        "    loss = preds[:, class_idx]\n",
        "grads = tape.gradient(loss, conv_outputs)[0]\n",
        "\n",
        "# Compute the channel-wise mean of the gradients\n",
        "weights = tf.reduce_mean(grads, axis=(0, 1))\n",
        "\n",
        "# Multiply each channel in the feature map array by \"how important this channel is\" with regard to the class\n",
        "cam = np.ones(conv_outputs.shape[1:3], dtype=np.float32)\n",
        "for i, w in enumerate(weights):\n",
        "    cam += w * conv_outputs[0, :, :, i]\n",
        "# Normalize the heatmap between 0 and 255\n",
        "heatmap = cam.numpy()\n",
        "heatmap = cv2.resize(heatmap, (224,224))\n",
        "heatmap = np.maximum(heatmap, 0)\n",
        "heatmap = (heatmap - np.min(heatmap)) / (np.max(heatmap) - np.min(heatmap) + 1e-8)\n",
        "heatmap = (heatmap * 255).astype(np.uint8)\n",
        "# Apply a color map to the heatmap\n",
        "jet = cm.get_cmap(\"jet\")\n",
        "heatmap = jet(heatmap)\n",
        "heatmap = np.uint8(heatmap * 255)\n",
        "\n",
        "# Convert the heatmap to RGB format\n",
        "heatmap = cv2.cvtColor(heatmap, cv2.COLOR_RGBA2RGB)\n",
        "\n",
        "# Resize the heatmap to be the same size as the original image\n",
        "heatmap = cv2.resize(heatmap, (224,224))\n",
        "\n",
        "# Combine the heatmap with the original image\n",
        "superimposed_img = cv2.addWeighted(np.array(img), 0.5, heatmap, 0.5, 0)\n",
        "\n",
        "# Show the result\n",
        "plt.imshow(superimposed_img)\n",
        "plt.axis('off')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "GmQ9lRET5oVW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UAC-kWHi5qzn"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}